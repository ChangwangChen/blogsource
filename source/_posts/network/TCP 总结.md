---
title: TCP 总结
date: 2020-08-20 13:50:45
categories: Network
tags: [network]
---

### 问题1 SYN 默认超时时间

Server端收到 Client 发送的 SYN 后会直接发送 SYN-ACK 数据包, 并将 Client 放入 SYN Queue. 如果此时 Client 下线, Server 迟迟接受不到 ACK, 那么 Server 会在一段时间内不断重新发送 SYN-ACK 数据包, 知道达到最大重试次数(tcp_synack_retries). Linux系统中, 默认重试 5 次, 重试间隔时间从 1s 开始指数增长, 5 次重试时间间隔分别为: 1s, 2s, 4s, 8s, 16s, 总共 31s, 第 5 次发出后还要在等待 32s 才知道也超时, 所以总共需要 31s + 32s = 63s 才会断开链接.

### 问题1 SYN Flood Attack: SYN 半链接洪水攻击

由于 TCP SYN Queue 的大小有限, 所以在大量的恶意客户端发送了 SYN 数据包之后直接下线, Server 端会将 SYN Queue耗尽, 让正常客户端的链接无法处理. TCP 有多种方案可以缓解这种攻击:

1. 开启 tcp_syncookies 选项
   
   当 SYN Queue 满了之后, 开启 tcp_syncookies 选项, TCP 会通过算法将 `原地址端口`, `目标地址端口` 和 `时间戳` 打造出特别的 Sequence Number返回给客户端, 如果是攻击者不会回应, 正常的客户端会在 ACK 中携带这个特殊的序列号, Server 段会解析出来客户段的信息并建立链接.
   `千万不要使用 tcp_syncookies 来处理正常的高负载链接情景`. 

2. 减少 tcp_syn_retries 次数
   
   减少此配置, 可以减少 Server 重试发送 SYN-ACK 数据包的次数, 减少超时时间.

3. 增大 tcp_max_syn_backlog (SYN Queue) 大小
   
   增大半链接队列的数目, 缓存更多的 SYN 链接. `此方法在处理 SYN Flood Attack 中不太适用`.

4. 设置 tcp_abort_on_overflow
   
   SYN Queue 满了之后直接丢弃新的 SYN 链接.

### 问题3 ISN(初始序列号) 选择

`ISN不能是固定数字`. 因为在 TCP 短时间内重连之后, 会导致 TCP 数据包的乱序. RFC793 中说, ISN 会和一个假的时钟绑定, 这个时钟每隔 4 微秒对 ISN 加 1, 直到 2^32(`TCP头部的 Sequence Number 占用 32 位`) 之后重新开始. 可以计算一个 ISN 周期是 4.55 小时. 假设 TCP 数据包的 MSL(Maximum Segment Lifetime) 小于 4.55 小时, 我们不会重用到 ISN.

### 问题4 为什么要有 TIME_WAIT 状态

TCP 的状态图中, 主动关闭的一方最终都会到达 TIME_WAIT 状态, 在等待 2MSL(`RFC793 定义 MSL 为2分钟, Linux 为30秒`) 的时间之后, 进入 CLOSED 状态正式关闭 Socket 链接. 需要 TIME_WAIT 状态的原因有2个:

1. TIME_WAIT 确保对方能够收到最后的 ACK (这里只会在此状态中收到对方重发的 FIN, 返回 ACK)
2. 确保本端之前发送的数据包全部都消失, 不会影响后续使用同一端口创建的链接.  2MSL 的时间此 socket 会被占用.

### 问题5  LAST_ACK 状态时怎么处理?

被动关闭的一方在发送 FIN 之后进入 LAST_ACK 状态, 期望收到对方返回 ACK 而进入 CLOSED 状态来关闭链接. 由于网络环境复杂, 可能出现的几种状态如下:

1. 顺利收到 ACK, 直接进入 CLOSED 而关闭链接
2. 没有收到 ACK, 超时之后重传 FIN
- 2.1 对方处于 TIME_WAIT 状态时, 对方收到 FIN 之后会再次发送 ACK, 本端收到 ACK 后进入 CLOSED 状态并关闭链接
- 2.2 对方已经进入 CLOSED 状态并关闭链接, 对方会发送 RST, 本端收到 RST 后进入 CLOSED 状态并关闭链接
3. 对方机器宕机, 此端会进入重传机制, 直到重传超时关闭链接并进入 CLOSED 状态

`总之, 被动关闭的一方在 LAST_ACK 状态一定会进入 CLOSED 状态`.

### 问题6 大量 TIME_WAIT 怎么解决?

大量的 TIME_WAIT 状态会消耗服务器的资源, 特别是端口号(端口号总数有限, 不大于 65535). 对于这种情况我们可以通过设置内核参数 `tcp_tw_reuse` 和 `tcp_timestamps` 来缓解. 使用此方法需要注意:

1. 必须同时开启这两个选项. `tcp_timestamps` 需要 socket 双方都开启.
2. `tcp_tw_recycle` 选项已经在 Linux 4.11 之后的版本中移除, 并且在开启此选项时, 在 NAT 网络环境中会造成严重问题, 所以需要谨慎开启.
3. 关于增加 `tcp_max_tw_buckets`. 此选项默认是 18000, 超过之后, 系统会直接清理掉并打印警告(`time wait bucket table overflow`).

`自我感觉还是应用程序出了问题, 需要排查`.

### 问题7 TCP重传机制

TCP 要保证所有的数据都到达并被接收, 所以要有重传机制.

接收方发送 ACK 确认只会确认最后一个连续的包, 并且 SeqNum 和 ACK 都是以字节为单位, 所以 ACK 的时候, 不能够跳着确认, 只能 ACK 接收到的最大的连续的包.

发送方重传的触发有 2 中情况:
1. 超时重传
   
   发送方会死等未确认数据包的 ACK, 当达到超时时间之后, 才会重传为确认的数据包

2. 快速重传
   
    使用数据驱动, 发送方在连续 3 次收到相同的 ACK 时候, 直接重传数据

#### 超时重传

超时重传时, 发送方只有在超过超时时间未收到数据包的 ACK, 才会重传数据. 这种情况会造成大量的等待, 产生浪费.

此机制下, 重传数据的时候会有 2 中选择:
- 只重传为收到 ACK 的数据
  
  此方法会节省宽带, 但是比较慢, 如果大量的传输失败, 则需要较长时间进行重传

- 重传 timeout 后的所有数据
  
  此方法较快, 但是可能会在成宽带的浪费


#### 快速重传

快速重传无需等待 timeout 的时间, 发送方会根据 ACK 的数据来自动发现数据丢失并进行重传. 但是重传的时候也面临和超时重传相同的问题, 不确定具体丢失数据包的序号, 只能依次重传或者全部重传.

- SACK (Selective Acknowledgment)
  
  此方式需要在接收端的 ACK 数据包头部中加入 SACK 的信息, `告诉发送方已经收到数据包的序列号`. 需要 socket 双方都打开 `tcp_sack` 选项来开启(Linux 2.4 之后默认开启).

  注意:

  1. `发送方不能将收到的 SACK 完全当作 ACK`, 即: SACK 中不包含的 SeqNumber 的数据包不能够直接删除, 因为有的时候接收方可能是因为内存等原因将接收的乱序数据包从接收缓存中删除.
  2. `SACK会消耗发送方的资源`, 恶意的返回 SACK 会导致发送方一直重复发送数据.
   
- D-SACK (Duplicate SACK) 重复收到数据
  
    `使用 SACK 来告诉发送方重复发送了哪些数据`. D-SACK 使用 SACK 的第一段来做标志:

    - 如果 SACK 的第一段的范围被 ACK 所覆盖, 那么就是 D-SACK
    - 如果 SACk 的第一段被第二段覆盖, 那么就是 D-SACK

引入了 D-SACK 有以下几点好处:

1. 发送方可以知道是数据包丢失还是 ACK 包丢失
2. 发送方会知道是不是因为 timeout 太小导致的重传
3. 网络上出现先发的数据包后达到(reordering)
4. 网络上是不是把发送的数据包复制了

### 问题8 TCP KeepAlive 机制

TCP 通过 3 个选项来维持链接的活跃, 达到一定条件的时候会关闭链接.

- tcp_keepalive_time
  
  TCP 链接空闲(IDLE)达到这个秒数的时候, 会开始发送 KeepAlive 探测包. `默认: 7200s`.

- tcp_keepalive_intvl

  TCP 发送 KeepAlive 探测包的时间间隔, 秒数. `默认: 75s`

- tcp_keepalive_probes
  
  TCP 在发送了多少个 KeepAlive 探测包都没有收到回应之后, 开始关闭链接. `默认: 9`.

所以, 在默认情况下, TCP 在经历了大约 `2小时11分钟` 的空闲加上 KeepAlive 探测之后会关闭链接.

### 问题9 RTT(Round Trip Time: 往返时间)的计算

TCP 的重传机制严重依赖 Timeout 超时时间, 并且由于 TCP 底层网络环境的动态变化, 超时时间不能设置成固定值. 所以 TCP 引入了 RTT 的概念, `一个数据包从发出到接收到 ACK 的时间间隔`. TCP 根据这个值来设置 RTO(`Retransmission TimeOut`), 提高重传机制的准确率. 计算 RTO 的几个算法介绍如下.

#### 经典算法

RFC 793 中定义如下:
1. 首先采样 RTT, 记录最近几次 RTT
2. 然后做平滑计算 SRTT(Smoothed RTT)
   
   SRTT = ( α * SRTT ) + ((1- α) * RTT)  `α 在0.8到0.9之间`
3. 计算 RTO
   
   RTO = min [ UBOUND,  max [ LBOUND,   (β * SRTT) ]  ]

   其中: 
   - UBOUND是最大的 timeout 时间, 上限值
   - LBOUND是最小的 timeout 时间, 下限值
   - β 在 1.3 到 2.0 之间

#### Karn/Partidge 算法
上面的算法会有一个问题, RTT 样本时间的选择, 会对最终 RTO 的计算产生影响(不准确导致重传机制不会高效). 计算出来的 RTO 没法准确的呈现当时的网络状态.

Karn/Partidge 算法对上述经典算法做出了改进: `忽略重传, 不把重传的 RTT 做采样`.

但是, 这样出来会有其他的问题, 比如`某个时刻开始, 网络出现抖动, 产生了比较大的延时从而导致需要重传所有的数据包(以为发生抖动之前网络正常, 所以计算出来的 RTO 会比较小, 导致数据包都会被判断超时), 又由于此算法规定重传的 RTT 不做计算, 所以 RTO 不会被更新, 导致后续的所有数据包都会被重传, 直到网络恢复正常`. 总结起来就是此算法`无法应对网络抖动导致 RTT 增加的情况`.

所以 Karn 算法使用了取巧的方式, 只要发生了重传, 直接将当前的 RTO 翻倍. 这种暴力的方式没有办法准确的呈现当前网络的状况.

#### Jacobson/Karels 算法
上述两种算法都是 `加权移动平均`, 这种方法最大的问题是如果 RTT 出现波动很难被发现. 所以有人就提出了新的算法, 引入最新的 RTT 的采样和平滑过的 SRTT 的差距做因子来计算. 公式如下:

```
SRTT = SRTT + α (RTT – SRTT)  —— 计算平滑RTT

DevRTT = (1-β)*DevRTT + β*(|RTT-SRTT|) ——计算平滑RTT和真实的差距（加权移动平均）

RTO= µ * SRTT + ∂ *DevRTT —— 神一样的公式
```

在 Linux 下, α = 0.125，β = 0.25， μ = 1，∂ = 4. (`不要问我为什么, 但它就是工作的很好`)


### 问题10 TCP 滑动窗口机制

TCP 是可靠并且有序的传输协议. 所以 TCP 需要解决可靠传输(`ACK机制保证`)和乱序问题(`重传机制保证`). 同时, TCP 需要知道网络中的数据处理带宽和处理速度的实际情况, 从而避免出现网络拥塞导致出现丢包.

TCP 引入了一些技术来网络流控, Sliding Window就是其中之一. `TCP头里有一个字段叫Window，又叫Advertised-Window，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来`. 滑动窗口是 TCP 的被动流控, 拥塞窗口是主动流控.

滑动窗口的处理过程:
1. 三次握手的时候双方都会通知自己能够接收数据的最大字节数, 做为对方能够发送未 ACK 数据的最大值
2. 发送方发送了数据之后, 窗口中还能发送数据的大小 = 窗口大小 - 已发送数据的大小
3. 发送方收到 ACK 后, 会将滑动窗口的左边界往右移动相应的数目, 此时 ACK 中的 WIN 会决定右边界也是否向右滑动, WIN 的大小是相对左边界的大小

#### Zero Window

上面的流程中, 滑动窗口的大小可能会变成 0, 此时发送方将无法在发送数据. 为了解决这个问题, TCP 使用了 `Zero Window Probe(零窗口探测)` 技术, 发送方会发送 ZWP 包给接收方, 让接收方 ACK 自己 WIN 的尺寸. 此探测会发送 3 次, 每次大约 30 - 60 秒(具体的实现会有差异), 3 次过后 WIN 还是 0 的时候, 有的 TCP 实现会发送 RST 报文来关闭链接.

注意: TCP 中有出现等待的地方就会有可能遭受到攻击, 恶意的客户端会在建立链接之后将自己的 WIN 设置为 0, 导致服务器一直等待 ZWP, 直到资源耗尽.


#### Silly Window Syndrome(糊涂窗口综合症)

接收方忙碌, 来不及处理接收缓存中的数据, 就会导致发送方收到的 WIN 越来越小. 会出现接收方腾出及字节的 WIN, 发送方就会马上发送数据, 导致链接的利用率下降.

解决方案:
1. 问题由于接收方引起, 就会在 window size 小于某值的时候, 直接返回 0 给发送方. 直到 window 恢复到 MSS 大小或者达到接收缓存的一半, 在返回 WIN, 让发送方开始发送数据
2. 问题是发送方引起的, 就会使用 Nagle 算法. 等到 WIN >= MSS, 或者数据尺寸 >= MSS, 或者收到发送数据的 ack(时间达到 40 ms), 才会发送数据

注意: 
- TCP_NODELAY 开启 Nagle算法, 自动延时发送数据
- TCP_CORK 开启的时候, 表示手动打开延时发送, 直到`手动关闭此选项`或者`达到 200ms`的时候, 才会发送数据
- TCP_NODELAY 是发送方的限流配置, TCP_QUICKACK 是接收放的限流配置


### 问题11 Congestion Handling 拥塞控制机制











- 三次握手
- 四次挥手
- 滑动窗口
- 拥塞控制
- 超时重传
- Keep-Alive